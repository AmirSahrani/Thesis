{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib as dl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembly and cleaning\n",
    "First we assemble all the data, and in some cases we have to reformat some of the sequences. when all is done we clean the data by making everything lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df,file):\n",
    "    if file == 'František': # František has a different format\n",
    "        df[\"sequence\"] = df['sequence'].str.replace(\"x\", \"t\")\n",
    "        df['sequence'] = df['sequence'].str.replace(\"o\", \"h\")\n",
    "        df['sequence'] = df['sequence'].str.replace(\"f\", \"x\")\n",
    "    if file == 'Kaleem': # Kaleem has a different format\n",
    "        df['sequence'] = df['sequence'].str.replace(\"y\", \"x\")\n",
    "    df['sequence'] = df['sequence'].str.lower()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Amir','DavidV',\"František\",'Kaleem','Pierre', 'DavidKL']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    f = pd.read_csv(f'Audit_data/{file}.csv', header = 0)\n",
    "    f = cleaning(f,file)\n",
    "    df = pd.concat([df,f], axis = 0, ignore_index = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting original data\n",
    "Now we need to get the original data form the tosser's to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachelor_f = pd.read_csv('bachelor_data.csv', header = 0)\n",
    "marathon_f = pd.read_csv('marathon_data.csv', header = 0)\n",
    "bachelor = pd.DataFrame(bachelor_f)\n",
    "marathon = pd.DataFrame(marathon_f)\n",
    "reported = []\n",
    "start = []\n",
    "for _,i in df.iterrows():\n",
    "    if i['person'] == 'kaleemU' and i['sequence_id'] == 25:\n",
    "        reported.append(bachelor.loc[((bachelor['sequence_id'] == i['sequence_id']) & (bachelor['person'] == 'irmaT'))]['sequence'].values[0])\n",
    "        start.append(bachelor.loc[((bachelor['sequence_id'] == i['sequence_id']) & (bachelor['person'] == 'irmaT'))]['start'].values[0])\n",
    "    elif i['group'] == 'bachelor':    \n",
    "        reported.append(bachelor.loc[((bachelor['sequence_id'] == i['sequence_id']) & (bachelor['person'] == i['person']))]['sequence'].values[0])\n",
    "        start.append(bachelor.loc[((bachelor['sequence_id'] == i['sequence_id']) & (bachelor['person'] == i['person']))]['start'].values[0])\n",
    "    else:\n",
    "        reported.append(marathon.loc[((marathon['sequence_id'] == i['sequence_id']) & (marathon['person'] == i['person']))]['sequence'].values[0])\n",
    "        start.append(marathon.loc[((marathon['sequence_id'] == i['sequence_id']) & (marathon['person'] == i['person']))]['start'].values[0])\n",
    "df['reported_sequence'] = reported\n",
    "df['start'] = start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switcher(audit, report):\n",
    "    if audit[0] == report[0]:\n",
    "        return audit # if the first letter is the same, no need to switch\n",
    "    elif audit[0] != report[0] and audit[0] != 'u':\n",
    "        audit = audit.replace(\"h\", \"V\") # replace h with a placeholder\n",
    "        audit = audit.replace(\"t\", \"h\") # replace t with h\n",
    "        audit = audit.replace(\"V\", \"t\") # replace placeholder with t\n",
    "        return audit\n",
    "    elif audit[-1] == report[-1]:\n",
    "        return audit\n",
    "    elif audit[-1] != report[-1]:\n",
    "        audit = audit.replace(\"h\", \"V\")\n",
    "        audit = audit.replace(\"t\", \"h\")\n",
    "        audit = audit.replace(\"V\", \"t\")\n",
    "        return audit\n",
    "    else:\n",
    "        return \"manually check\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for _,i in df.iterrows():\n",
    "    sequences.append(switcher(i['sequence'],i['reported_sequence']))\n",
    "df['corrected_sequence'] = sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_sequence'] = df['corrected_sequence'].str.replace(\"x\", \"\")\n",
    "df['cleaned_sequence'] = df['cleaned_sequence'].str.replace(\"u\", \"\")\n",
    "df['cleaned_reported_sequence'] = df['reported_sequence'].str.replace(\"x\", \"\").replace(\"u\", \"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing\n",
    "Now that we have both reported and audited sequences we can start comparing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jillR 36\n",
      "pierreG 8\n",
      "davidV 52\n",
      "pierreG 141\n",
      "kaleemU 20\n",
      "pierreG 48\n",
      "pierreG 138\n",
      "amirS 61\n",
      "davidV 42\n",
      "kaleemU 21\n",
      "davidKL 53\n",
      "ingeborgR 55\n",
      "madlenH 3\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "correct = []\n",
    "for _,i in df.iterrows():\n",
    "    if i['cleaned_sequence'] == i['cleaned_reported_sequence']:\n",
    "        correct.append(1)\n",
    "        print(i['person'], i['sequence_id'])\n",
    "    else:\n",
    "        correct.append(0)\n",
    "df['correct'] = correct\n",
    "print(sum(df['correct']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this we can see that 13 trails are completely correct, even without considering possible 1-off errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive approach\n",
    "Using a naive approach we can see that Pierre's data is extremely accurate with only 2 mistakes. everything else is still unclear, presumably because of misalignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_check(a,b):\n",
    "    errors = []\n",
    "    succes = []\n",
    "    for i in range(min(len(a),len(b))):\n",
    "        if a[i] == b[i] or (a[i] == \"_\" or b[i] == \"_\"):\n",
    "            errors.append(0)\n",
    "        else:\n",
    "            errors.append(1)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    52\n",
       "4    39\n",
       "2    34\n",
       "3     1\n",
       "0     0\n",
       "Name: sequence_errors, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_errors = []\n",
    "for _,i in df.iterrows():\n",
    "    sequences_errors.append(sum(naive_check(i['cleaned_sequence'],i['cleaned_reported_sequence'])))\t\n",
    "df['sequence_errors'] = sequences_errors\n",
    "df['sequence_errors'].head().sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def get_minimum_penalty(x:str, y:str, pxy:int, pgap:int):\n",
    "    \"\"\"\n",
    "    Function to find out the minimum penalty\n",
    " \n",
    "    :param x: pattern X\n",
    "    :param y: pattern Y\n",
    "    :param pxy: penalty of mis-matching the characters of X and Y\n",
    "    :param pgap: penalty of a gap between pattern elements\n",
    "    \"\"\"\n",
    " \n",
    "    # initializing variables\n",
    "    i = 0\n",
    "    j = 0\n",
    "     \n",
    "    # pattern lengths\n",
    "    m = len(x)\n",
    "    n = len(y)\n",
    "     \n",
    "    # table for storing optimal substructure answers\n",
    "    dp = np.zeros([m+1,n+1], dtype=int) #int dp[m+1][n+1] = {0};\n",
    " \n",
    "    # initialising the table\n",
    "    dp[0:(m+1),0] = [ i * pgap for i in range(m+1)]\n",
    "    dp[0,0:(n+1)] = [ i * pgap for i in range(n+1)]\n",
    " \n",
    "    # calculating the minimum penalty\n",
    "    i = 1\n",
    "    while i <= m:\n",
    "        j = 1\n",
    "        while j <= n:\n",
    "            if x[i - 1] == y[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i - 1][j - 1] + pxy,\n",
    "                                dp[i - 1][j] + pgap,\n",
    "                                dp[i][j - 1] + pgap)\n",
    "            j += 1\n",
    "        i += 1\n",
    "     \n",
    "    # Reconstructing the solution\n",
    "    l = n + m   # maximum possible length\n",
    "    i = m\n",
    "    j = n\n",
    "     \n",
    "    xpos = l\n",
    "    ypos = l\n",
    " \n",
    "    # Final answers for the respective strings\n",
    "    xans = np.zeros(l+1, dtype=int)\n",
    "    yans = np.zeros(l+1, dtype=int)\n",
    "     \n",
    " \n",
    "    while not (i == 0 or j == 0):\n",
    "        #print(f\"i: {i}, j: {j}\")\n",
    "        if x[i - 1] == y[j - 1]:       \n",
    "            xans[xpos] = ord(x[i - 1])\n",
    "            yans[ypos] = ord(y[j - 1])\n",
    "            xpos -= 1\n",
    "            ypos -= 1\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif (dp[i - 1][j - 1] + pxy) == dp[i][j]:\n",
    "         \n",
    "            xans[xpos] = ord(x[i - 1])\n",
    "            yans[ypos] = ord(y[j - 1])\n",
    "            xpos -= 1\n",
    "            ypos -= 1\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "         \n",
    "        elif (dp[i - 1][j] + pgap) == dp[i][j]:\n",
    "            xans[xpos] = ord(x[i - 1])\n",
    "            yans[ypos] = ord('_')\n",
    "            xpos -= 1\n",
    "            ypos -= 1\n",
    "            i -= 1\n",
    "         \n",
    "        elif (dp[i][j - 1] + pgap) == dp[i][j]:       \n",
    "            xans[xpos] = ord('_')\n",
    "            yans[ypos] = ord(y[j - 1])\n",
    "            xpos -= 1\n",
    "            ypos -= 1\n",
    "            j -= 1\n",
    "         \n",
    " \n",
    "    while xpos > 0:\n",
    "        if i > 0:\n",
    "            i -= 1\n",
    "            xans[xpos] = ord(x[i])\n",
    "            xpos -= 1\n",
    "        else:\n",
    "            xans[xpos] = ord('_')\n",
    "            xpos -= 1\n",
    "     \n",
    "    while ypos > 0:\n",
    "        if j > 0:\n",
    "            j -= 1\n",
    "            yans[ypos] = ord(y[j])\n",
    "            ypos -= 1\n",
    "        else:\n",
    "            yans[ypos] = ord('_')\n",
    "            ypos -= 1\n",
    " \n",
    "    # Since we have assumed the answer to be n+m long,\n",
    "    # we need to remove the extra gaps in the starting\n",
    "    # id represents the index from which the arrays\n",
    "    # xans, yans are useful\n",
    "    id = 1\n",
    "    i = l\n",
    "    while i >= 1:\n",
    "        if (chr(yans[i]) == '_') and chr(xans[i]) == '_':\n",
    "            id = i + 1\n",
    "            break\n",
    "         \n",
    "        i -= 1\n",
    " \n",
    "    # Printing the final answer\n",
    "    # print(f\"Minimum Penalty in aligning the genes = {dp[m][n]}\")\n",
    "    # print(\"The aligned genes are:\")   \n",
    "    # X\n",
    "    i = id\n",
    "    x_seq = \"\"\n",
    "    while i <= l:\n",
    "        x_seq += chr(xans[i])\n",
    "        i += 1\n",
    " \n",
    "    # Y\n",
    "    i = id\n",
    "    y_seq = \"\"\n",
    "    while i <= l:\n",
    "        y_seq += chr(yans[i])\n",
    "        i += 1\n",
    "    return [x_seq, y_seq]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "markings = []\n",
    "errors = []\n",
    "for _,i in df.iterrows():\n",
    "    x = get_minimum_penalty(i['cleaned_sequence'],i['cleaned_reported_sequence'],1,3)\n",
    "    errors.append(naive_check(x[0],x[1]))\n",
    "    if sum(errors[-1]) > 9:\n",
    "        markings.append(\"x\")\n",
    "    else:\n",
    "        markings.append(\"\") \n",
    "df['marked'] = markings\n",
    "df['errors'] = errors\n",
    "\n",
    "# df = df.explode('errors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['person_factor'] = pd.factorize(df['person'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "h\n",
      "t\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "t\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "t\n",
      "t\n",
      "t\n",
      "h\n",
      "t\n",
      "h\n",
      "t\n",
      "h\n",
      "t\n",
      "h\n",
      "t\n",
      "h\n",
      "t\n",
      "h\n",
      "h\n",
      "h\n",
      "t\n",
      "h\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "h\n",
      "t\n",
      "t\n",
      "t\n",
      "t\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "h\n",
      "t\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "last = \"\"\n",
    "decoded = []\n",
    "for _, i in df.iterrows():\n",
    "    decoded_str = \"\"\n",
    "    for index,letter in enumerate(i['cleaned_sequence']):\n",
    "        if index == 0:\n",
    "            if letter == df.loc[_]['start']:\n",
    "                decoded_str = decoded_str + 's'\n",
    "            else:\n",
    "                decoded_str = decoded_str +'f'\n",
    "        else:\n",
    "            if letter == last:\n",
    "                decoded_str = decoded_str +'s'\n",
    "            else:\n",
    "                decoded_str = decoded_str +'f'\n",
    "        last = letter\n",
    "    decoded.append(decoded_str)\n",
    "df['decoded_sequence'] = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns must have matching element counts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amisa\\Documents\\Python\\Thesis\\Audit_notebook.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amisa/Documents/Python/Thesis/Audit_notebook.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mexplode([\u001b[39m'\u001b[39;49m\u001b[39merrors\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdecoded_sequence\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\amisa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:8351\u001b[0m, in \u001b[0;36mDataFrame.explode\u001b[1;34m(self, column, ignore_index)\u001b[0m\n\u001b[0;32m   8349\u001b[0m     \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m columns[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m   8350\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(counts0 \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m[c]\u001b[39m.\u001b[39mapply(mylen)):\n\u001b[1;32m-> 8351\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcolumns must have matching element counts\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   8352\u001b[0m     result \u001b[39m=\u001b[39m DataFrame({c: df[c]\u001b[39m.\u001b[39mexplode() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m columns})\n\u001b[0;32m   8353\u001b[0m result \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mjoin(result)\n",
      "\u001b[1;31mValueError\u001b[0m: columns must have matching element counts"
     ]
    }
   ],
   "source": [
    "df.explode(['errors', 'decoded_sequence'])\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d6c2a5ed63a7b8262a585c7d8a51c2575e7dc606b01ded3ffcdd65d619f40ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
